<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XB18VJ73B7"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-XB18VJ73B7');
    </script>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Suvash Sedhain | How exactly is machine learning used in recommendation engines?</title>

    <!-- Open Graph -->
    <meta property="og:title" content="How exactly is machine learning used in recommendation engines?" />
    <meta property="og:description" content="An overview of how ML techniques are used across different recommender system models — content-based, collaborative filtering, and hybrid approaches." />
    <meta property="og:url" content="https://mesuvash.github.io/blog/2015/Quora-Machine-Learning-In-Recommender-Systems/" />
    <meta property="og:type" content="article" />

    <!-- Twitter Card -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="How exactly is machine learning used in recommendation engines?" />
    <meta name="twitter:description" content="An overview of how ML techniques are used across different recommender system models — content-based, collaborative filtering, and hybrid approaches." />

    <link rel="shortcut icon" href="/assets/img/favicon.ico">
    <link rel="stylesheet" href="/assets/css/blog.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body, {delimiters:[{left:'$$',right:'$$',display:true},{left:'$',right:'$',display:false}]});"></script>
</head>
<body>

<header class="site-header">
  <div class="header-inner">
    <a href="/" class="site-title">Suvash Sedhain</a>
    <nav class="site-nav">
      <a href="/">About</a>
      <a href="/blog/" class="active">Blog</a>
      <a href="/projects/">Projects</a>
      <a href="/publications/">Publications</a>
    </nav>
  </div>
</header>

<div class="page-content">

  <header class="post-header">
    <h1>How exactly is machine learning used in recommendation engines?</h1>
    <p class="post-meta">March 15, 2015</p>
    <p class="follow-links">Follow me on <a href="https://x.com/suvsh" target="_blank" rel="noopener">X</a> and <a href="https://www.linkedin.com/in/suvashsedhain/" target="_blank" rel="noopener">LinkedIn</a></p>
    <div class="share-buttons">
        <span>Share:</span>
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fmesuvash.github.io%2Fblog%2F2015%2FQuora-Machine-Learning-In-Recommender-Systems%2F&text=How%20exactly%20is%20machine%20learning%20used%20in%20recommendation%20engines%3F" target="_blank" rel="noopener" title="Share on X">
            <svg viewBox="0 0 24 24"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg>
        </a>
        <a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fmesuvash.github.io%2Fblog%2F2015%2FQuora-Machine-Learning-In-Recommender-Systems%2F" target="_blank" rel="noopener" title="Share on LinkedIn">
            <svg viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 01-2.063-2.065 2.064 2.064 0 112.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
        </a>
        <a href="https://www.reddit.com/submit?url=https%3A%2F%2Fmesuvash.github.io%2Fblog%2F2015%2FQuora-Machine-Learning-In-Recommender-Systems%2F&title=How%20exactly%20is%20machine%20learning%20used%20in%20recommendation%20engines%3F" target="_blank" rel="noopener" title="Share on Reddit">
            <svg viewBox="0 0 24 24"><path d="M12 0A12 12 0 000 12a12 12 0 0012 12 12 12 0 0012-12A12 12 0 0012 0zm5.01 4.744c.688 0 1.25.561 1.25 1.249a1.25 1.25 0 01-2.498.056l-2.597-.547-.8 3.747c1.824.07 3.48.632 4.674 1.488.308-.309.73-.491 1.207-.491.968 0 1.754.786 1.754 1.754 0 .716-.435 1.333-1.01 1.614a3.111 3.111 0 01.042.52c0 2.694-3.13 4.87-7.004 4.87-3.874 0-7.004-2.176-7.004-4.87 0-.183.015-.366.043-.534A1.748 1.748 0 014.028 12c0-.968.786-1.754 1.754-1.754.463 0 .898.196 1.207.49 1.207-.883 2.878-1.43 4.744-1.487l.885-4.182a.342.342 0 01.14-.197.35.35 0 01.238-.042l2.906.617a1.214 1.214 0 011.108-.701zM9.25 12C8.561 12 8 12.562 8 13.25c0 .687.561 1.248 1.25 1.248.687 0 1.248-.561 1.248-1.249 0-.688-.561-1.249-1.249-1.249zm5.5 0c-.687 0-1.248.561-1.248 1.25 0 .687.561 1.248 1.249 1.248.688 0 1.249-.561 1.249-1.249 0-.687-.562-1.249-1.25-1.249zm-5.466 3.99a.327.327 0 00-.231.094.33.33 0 000 .463c.842.842 2.484.913 2.961.913.477 0 2.105-.056 2.961-.913a.361.361 0 000-.463.327.327 0 00-.231-.094c-.06 0-.12.02-.169.07-.572.573-1.7.76-2.546.76-.846 0-1.989-.187-2.561-.76a.291.291 0 00-.184-.07z"/></svg>
        </a>
    </div>
  </header>

  <article class="post-content">
    <p>Before diving into the detail, I would like to say that Collaborative Filtering algorithms are inherently based on similarity metrics, whether it's in user/item space (as in neighbourhood models) or latent space (as in factor models).
To answer the main question "where do ML techniques are used in recommendation engines", I would like to answer for various recommender system models with some examples</p>

<h4 id="content-based-recommendation-cbr">Content Based Recommendation (CBR):</h4>

<p>CBR provides personalized recommendation by matching user's interests with description and attributes of items. For CBR, we can use standard ML techniques like Logistic Regression, SVM, Decision tree etc. based on user and item features for making predictions for eg: extent of like or dislike. Then, we can easily convert the result to ranked recommendation</p>

<h4 id="collaborative-filtering-cf">Collaborative filtering (CF)</h4>

<p>Neighborhood models** are heuristics based models which uses similarity metrics, for eg : pearson similarity, cosine similarity,  for finding similar users and items. It is based on, very reasonable, heuristic that a person will like the items that are similar to previously liked items. Rating prediction in item based neighborhood models is given by weighted average of ratings on similar items as shown below</p>

$$\hat{r}_{u,i} = b_{u,i} + \frac{\sum_{j \in N(i,k,u)}{s_{i,j} (r_{u,j} -   b_{u,j})}}{\sum_{j \in N(i,k,u)} s_{i,j} }$$

<p>where, $N(i, k, u)$ is a set of k items that are similar to i and rated by the user $u$; $s_{i,j}$ is a similarity function (cosine or pearson correlation).
As there is no learning involved in above equation, any ML guy will say that this sucks (although it works pretty well in practice). So, in a quest of 1 million bucks (Netflix challenge), some smart people (Yehuda Koren et al.) thought about it and reformulated it as</p>

$$\hat{r}_{u,i} = b_{u,i} + \sum_{j \in N(i,k,u)}{\theta_{i,j}^{u} (r_{u,j} -   b_{u,j})}$$

<p>Now any ML guy will say "<em>Ohhh wait, it looks like linear regression  with *$\theta_{i,j}^{u}$  as *parameters</em>". Now the ML guy is happy :).</p>

<p>So, Instead of using ad-hoc heuristic based $s_{i,j}$ to weight the ratings, now  the weights, $\theta_{i,j}^{u}$, are learned. Note that, it  was crucial in winning Netflix prize. This is just an instance, out of many, of ML in recommendation.</p>

<p><strong>Matrix Factorization</strong> learns user and item latent factors ($U$ an $V$) by minimizing reconstruction error on observed ratings. Formally, in an optimization framework it is given as</p>

$$\begin{aligned} {\text{min}}\sum_{u,i} (r_{ui} - U_{u}^{T} V_{i})^{2} + \lambda (\left \| U \right \|_{2} ^{2} + \left \| V \right \|_{2}^{2})  \end{aligned}$$

<p>First of all, when there is an optimization technique involved, it's definitely a ML thing.
Let's make this more clear by converting it to our own favorite Linear regression problem. <strong><em>So if you fix any one of the latent factor, say $U$, then it becomes linear regression on $V$.</em></strong> This way of optimization is well known in literature as ALS(alternating Least Squares). Again, ML guy who knows linear regression is very happy :).</p>

<p>Bayesian ML people, who  not only want point estimates but also uncertainty of the estimates, will reformulate the same problem into probabilistic setting and learn in their own bayesian way.  For detail refer to the <a href="http://www.gatsby.ucl.ac.uk/~amnih/papers/bpmf.pdf" target="_blank"> paper.</a></p>

<p>Similarly, neural network guys have used Restricted Boltzmann machine for rating prediction (this was also crucial in winning Netflix challenge). For detail refer to the <a href="http://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf" target="_blank"> paper </a>.</p>

<h4 id="machine-learning-and-cold-start">Machine learning and Cold Start</h4>

<p>Cold start is a situation when a recommender system doesn't have any historical information about user or item and is unable to make personalized recommendations. Cold start is the worst nightmare of any recommender system researcher. So one way to deal with cold start is eliciting new user's preferences via initial interview. However, interview based elicitation is not useful as user often get bored when they are asked a series of questions. Now, ML guy can use his decision tree knowledge to learn a model that smartly chooses a minimum set of the question while learning user's preference.</p>

<p>Furthermore, there is a vast literature on Learning to rank for recommendation. Although, Learning to rank shares  DNA with Information retrieval, its more ML technique.</p>

<p>In a nutshell, Machine learning is very common in recommendation algorithms. Hence, the use of ML in recommendation solely depend upon your objective and reformulating the problem into your favorite ML algorithm (smart people, sometimes, come up with revolutionary new learning algorithms!!! ).</p>

  <div class="share-bottom">
    <p>Found this useful? Help someone else find it too.</p>
    <div class="share-buttons">
        <a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fmesuvash.github.io%2Fblog%2F2015%2FQuora-Machine-Learning-In-Recommender-Systems%2F&text=How%20exactly%20is%20machine%20learning%20used%20in%20recommendation%20engines%3F" target="_blank" rel="noopener" title="Share on X">
            <svg viewBox="0 0 24 24"><path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z"/></svg>
        </a>
        <a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fmesuvash.github.io%2Fblog%2F2015%2FQuora-Machine-Learning-In-Recommender-Systems%2F" target="_blank" rel="noopener" title="Share on LinkedIn">
            <svg viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 01-2.063-2.065 2.064 2.064 0 112.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"/></svg>
        </a>
        <a href="https://www.reddit.com/submit?url=https%3A%2F%2Fmesuvash.github.io%2Fblog%2F2015%2FQuora-Machine-Learning-In-Recommender-Systems%2F&title=How%20exactly%20is%20machine%20learning%20used%20in%20recommendation%20engines%3F" target="_blank" rel="noopener" title="Share on Reddit">
            <svg viewBox="0 0 24 24"><path d="M12 0A12 12 0 000 12a12 12 0 0012 12 12 12 0 0012-12A12 12 0 0012 0zm5.01 4.744c.688 0 1.25.561 1.25 1.249a1.25 1.25 0 01-2.498.056l-2.597-.547-.8 3.747c1.824.07 3.48.632 4.674 1.488.308-.309.73-.491 1.207-.491.968 0 1.754.786 1.754 1.754 0 .716-.435 1.333-1.01 1.614a3.111 3.111 0 01.042.52c0 2.694-3.13 4.87-7.004 4.87-3.874 0-7.004-2.176-7.004-4.87 0-.183.015-.366.043-.534A1.748 1.748 0 014.028 12c0-.968.786-1.754 1.754-1.754.463 0 .898.196 1.207.49 1.207-.883 2.878-1.43 4.744-1.487l.885-4.182a.342.342 0 01.14-.197.35.35 0 01.238-.042l2.906.617a1.214 1.214 0 011.108-.701zM9.25 12C8.561 12 8 12.562 8 13.25c0 .687.561 1.248 1.25 1.248.687 0 1.248-.561 1.248-1.249 0-.688-.561-1.249-1.249-1.249zm5.5 0c-.687 0-1.248.561-1.248 1.25 0 .687.561 1.248 1.249 1.248.688 0 1.249-.561 1.249-1.249 0-.687-.562-1.249-1.25-1.249zm-5.466 3.99a.327.327 0 00-.231.094.33.33 0 000 .463c.842.842 2.484.913 2.961.913.477 0 2.105-.056 2.961-.913a.361.361 0 000-.463.327.327 0 00-.231-.094c-.06 0-.12.02-.169.07-.572.573-1.7.76-2.546.76-.846 0-1.989-.187-2.561-.76a.291.291 0 00-.184-.07z"/></svg>
        </a>
    </div>
    <p class="follow-links">Follow me on <a href="https://x.com/suvsh" target="_blank" rel="noopener">X</a> and <a href="https://www.linkedin.com/in/suvashsedhain/" target="_blank" rel="noopener">LinkedIn</a></p>
  </div>

  </article>

  <div id="disqus_thread"></div>
  <script>
    var disqus_shortname = 'ssedhain';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

</div>

<footer class="site-footer">
  <div class="container">
    &copy; 2026 Suvash Sedhain
  </div>
</footer>

</body>
</html>
